чем отличается задача регресии от прогнозирования?
эпоха? и сколько раз и в каком случае меняются параметры сети(веса и порог) за одну эпоху.
градиентный спуск.
сделать лабу рабочей????


Головко Владимир Адамович
Туз Иван Сергеевич
Кафедра интеллектуальных информационных технологий (ИИТ)
Эпоха (Epoch): Эпоха представляет собой один проход по всем обучающим данным в процессе обучения нейронной сети. 
Например, если у вас есть 1000 обучающих примеров, и вы обучаете модель на этих примерах, то одна эпоха будет завершена,
когда модель пройдет через все 1000 примеров.

Изменение параметров сети за одну эпоху: Параметры сети, такие как веса и пороги, обновляются по мере обучения. 
В методе градиентного спуска, который широко используется при обучении нейронных сетей, 
параметры обновляются с использованием градиента функции потерь. 
Градиент указывает направление наискорейшего возрастания функции, поэтому обновление весов происходит в направлении, обратном градиенту, 
чтобы минимизировать функцию потерь.

Градиентный спуск: Это оптимизационный алгоритм, который используется для обучения модели, минимизируя функцию потерь. 
Градиент – это вектор, указывающий направление наискорейшего возрастания функции. 
Градиентный спуск итеративно обновляет параметры модели в направлении, противоположном градиенту, 
с тем чтобы найти локальный минимум функции потерь.
В каждой эпохе градиентный спуск проходит через все обучающие данные, рассчитывает градиент и обновляет параметры модели. 
Процесс повторяется до достижения определенного критерия останова, такого как заданное количество эпох или достижение минимальной ошибки.



вывод формулы изменения весов для сети с сигмойдной(не обяз). гл. не линейной!






формула для нюха Ежа:
F(зрения)=Нос^2 * 4 шипа
нос(то есть нюх) = sqrt(F(зрения)/4 шипа)